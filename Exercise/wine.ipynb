{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = dataset.target_names\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components = 2)\\nX_train = pca.fit_transform(X_train)\\nX_test = pca.transform(X_test)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\\nlda = LDA(n_components = 2)\\nX_train = lda.fit_transform(X_train, np.argmax(y_train, axis=1))\\nX_test = lda.transform(X_test)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components = 2)\n",
    "X_train = lda.fit_transform(X_train, np.argmax(y_train, axis=1))\n",
    "X_test = lda.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.decomposition import KernelPCA\\nkpca = KernelPCA(n_components = 2, kernel = 'rbf')\\nX_train = kpca.fit_transform(X_train)\\nX_test = kpca.transform(X_test)\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n",
    "X_train = kpca.fit_transform(X_train)\n",
    "X_test = kpca.transform(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 3, activation = 'softmax'))\n",
    "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.1055 - accuracy: 0.3662\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 1.0285 - accuracy: 0.4014\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.9691 - accuracy: 0.4648\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.9203 - accuracy: 0.5070\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8787 - accuracy: 0.5282\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8432 - accuracy: 0.5352\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.8118 - accuracy: 0.5493\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7832 - accuracy: 0.5563\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7558 - accuracy: 0.5845\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.6127\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.6127\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.6338\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6479\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6549\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6831\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7042\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7324\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7817\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7958\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8310\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8873\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.9014\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.9155\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.9366\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.9577\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.9789\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.9789\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9789\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9789\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2583 - accuracy: 0.9789\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9789\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9859\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2284 - accuracy: 0.9859\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9859\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9930\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9930\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9930\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1772 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec650139a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 5, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.023 0.08  0.898]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.012 0.016 0.972]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.015 0.024 0.961]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.998 0.001 0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.012 0.016 0.972]\n",
      " [0.    1.    0.   ]\n",
      " [0.012 0.016 0.972]\n",
      " [1.    0.    0.   ]\n",
      " [0.02  0.085 0.894]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.012 0.016 0.972]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    1.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "print(np.round(y_pred,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010359629988670349, 1.0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[14,  0,  0],\n",
       "       [ 0, 15,  0],\n",
       "       [ 0,  0,  7]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.confusion_matrix(np.argmax(y_test, axis=1),np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict</th>\n",
       "      <th>Actural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>class_2</td>\n",
       "      <td>class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>class_0</td>\n",
       "      <td>class_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>class_1</td>\n",
       "      <td>class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predict  Actural\n",
       "0   class_2  class_2\n",
       "1   class_1  class_1\n",
       "2   class_1  class_1\n",
       "3   class_2  class_2\n",
       "4   class_1  class_1\n",
       "5   class_0  class_0\n",
       "6   class_0  class_0\n",
       "7   class_0  class_0\n",
       "8   class_2  class_2\n",
       "9   class_1  class_1\n",
       "10  class_1  class_1\n",
       "11  class_0  class_0\n",
       "12  class_1  class_1\n",
       "13  class_0  class_0\n",
       "14  class_1  class_1\n",
       "15  class_0  class_0\n",
       "16  class_1  class_1\n",
       "17  class_0  class_0\n",
       "18  class_0  class_0\n",
       "19  class_0  class_0\n",
       "20  class_0  class_0\n",
       "21  class_2  class_2\n",
       "22  class_1  class_1\n",
       "23  class_2  class_2\n",
       "24  class_0  class_0\n",
       "25  class_2  class_2\n",
       "26  class_0  class_0\n",
       "27  class_1  class_1\n",
       "28  class_2  class_2\n",
       "29  class_0  class_0\n",
       "30  class_1  class_1\n",
       "31  class_1  class_1\n",
       "32  class_0  class_0\n",
       "33  class_1  class_1\n",
       "34  class_1  class_1\n",
       "35  class_1  class_1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Predict': target_names[np.argmax(y_pred, axis=1)], 'Actural': target_names[np.argmax(y_test, axis=1)]}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising results for Dimensionality reduce algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, np.argmax(y_train, axis = 1)\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, np.argmax(ann.predict(np.array([X1.ravel(), X2.ravel()]).T),axis=1).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n",
    "plt.title('Deep learning (Training set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, np.argmax(y_test, axis = 1)\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, np.argmax(ann.predict(np.array([X1.ravel(), X2.ravel()]).T),axis=1).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n",
    "plt.title('Deep learning (Testing set)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17ae21252f2b7fb43c77235fc47dd38ae5f55079d7f4853767dec83b7e048f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
