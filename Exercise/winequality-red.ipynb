{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/winequality-red.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 6, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
    "ann.add(tf.keras.layers.Dropout(0.3))\n",
    "ann.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'softmax'))\n",
    "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "40/40 [==============================] - 1s 5ms/step - loss: 1.3035 - accuracy: 0.4855 - val_loss: 1.0603 - val_accuracy: 0.5750\n",
      "Epoch 2/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.0182 - accuracy: 0.5754 - val_loss: 0.9971 - val_accuracy: 0.5750\n",
      "Epoch 3/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.9712 - accuracy: 0.5903 - val_loss: 0.9864 - val_accuracy: 0.6000\n",
      "Epoch 4/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.9494 - accuracy: 0.6052 - val_loss: 0.9774 - val_accuracy: 0.6000\n",
      "Epoch 5/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.9374 - accuracy: 0.6059 - val_loss: 0.9709 - val_accuracy: 0.5906\n",
      "Epoch 6/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.9226 - accuracy: 0.6231 - val_loss: 0.9735 - val_accuracy: 0.5781\n",
      "Epoch 7/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.9000 - accuracy: 0.6122 - val_loss: 0.9698 - val_accuracy: 0.5875\n",
      "Epoch 8/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8920 - accuracy: 0.6177 - val_loss: 0.9741 - val_accuracy: 0.5750\n",
      "Epoch 9/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8829 - accuracy: 0.6349 - val_loss: 0.9697 - val_accuracy: 0.5906\n",
      "Epoch 10/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8644 - accuracy: 0.6255 - val_loss: 0.9701 - val_accuracy: 0.5875\n",
      "Epoch 11/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8735 - accuracy: 0.6169 - val_loss: 0.9678 - val_accuracy: 0.5875\n",
      "Epoch 12/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8560 - accuracy: 0.6364 - val_loss: 0.9674 - val_accuracy: 0.5875\n",
      "Epoch 13/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8627 - accuracy: 0.6286 - val_loss: 0.9673 - val_accuracy: 0.6062\n",
      "Epoch 14/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8523 - accuracy: 0.6208 - val_loss: 0.9619 - val_accuracy: 0.5906\n",
      "Epoch 15/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8437 - accuracy: 0.6411 - val_loss: 0.9639 - val_accuracy: 0.5750\n",
      "Epoch 16/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8458 - accuracy: 0.6357 - val_loss: 0.9646 - val_accuracy: 0.5938\n",
      "Epoch 17/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8321 - accuracy: 0.6474 - val_loss: 0.9658 - val_accuracy: 0.5813\n",
      "Epoch 18/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8319 - accuracy: 0.6357 - val_loss: 0.9689 - val_accuracy: 0.6062\n",
      "Epoch 19/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8231 - accuracy: 0.6435 - val_loss: 0.9684 - val_accuracy: 0.5969\n",
      "Epoch 20/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8121 - accuracy: 0.6435 - val_loss: 0.9690 - val_accuracy: 0.6062\n",
      "Epoch 21/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8151 - accuracy: 0.6615 - val_loss: 0.9772 - val_accuracy: 0.6094\n",
      "Epoch 22/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.6513 - val_loss: 0.9721 - val_accuracy: 0.6125\n",
      "Epoch 23/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8031 - accuracy: 0.6568 - val_loss: 0.9756 - val_accuracy: 0.5844\n",
      "Epoch 24/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7975 - accuracy: 0.6599 - val_loss: 0.9724 - val_accuracy: 0.6219\n",
      "Epoch 25/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.8001 - accuracy: 0.6497 - val_loss: 0.9726 - val_accuracy: 0.6125\n",
      "Epoch 26/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.6755 - val_loss: 0.9691 - val_accuracy: 0.6094\n",
      "Epoch 27/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7837 - accuracy: 0.6607 - val_loss: 0.9834 - val_accuracy: 0.6219\n",
      "Epoch 28/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7940 - accuracy: 0.6575 - val_loss: 0.9661 - val_accuracy: 0.6156\n",
      "Epoch 29/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.6771 - val_loss: 0.9652 - val_accuracy: 0.6156\n",
      "Epoch 30/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7719 - accuracy: 0.6794 - val_loss: 0.9680 - val_accuracy: 0.6250\n",
      "Epoch 31/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7744 - accuracy: 0.6716 - val_loss: 0.9685 - val_accuracy: 0.6094\n",
      "Epoch 32/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.6935 - val_loss: 0.9771 - val_accuracy: 0.6219\n",
      "Epoch 33/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7570 - accuracy: 0.6779 - val_loss: 0.9900 - val_accuracy: 0.6125\n",
      "Epoch 34/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.6865 - val_loss: 0.9742 - val_accuracy: 0.6156\n",
      "Epoch 35/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.6888 - val_loss: 0.9883 - val_accuracy: 0.6094\n",
      "Epoch 36/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7502 - accuracy: 0.6833 - val_loss: 0.9763 - val_accuracy: 0.6313\n",
      "Epoch 37/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.6896 - val_loss: 0.9808 - val_accuracy: 0.6344\n",
      "Epoch 38/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7431 - accuracy: 0.6818 - val_loss: 0.9769 - val_accuracy: 0.6344\n",
      "Epoch 39/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.6904 - val_loss: 0.9797 - val_accuracy: 0.6375\n",
      "Epoch 40/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7263 - accuracy: 0.7052 - val_loss: 1.0195 - val_accuracy: 0.6062\n",
      "Epoch 41/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7251 - accuracy: 0.6912 - val_loss: 0.9970 - val_accuracy: 0.6187\n",
      "Epoch 42/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.6951 - val_loss: 0.9888 - val_accuracy: 0.6281\n",
      "Epoch 43/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.6951 - val_loss: 0.9846 - val_accuracy: 0.6313\n",
      "Epoch 44/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7057 - accuracy: 0.7154 - val_loss: 0.9853 - val_accuracy: 0.6219\n",
      "Epoch 45/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7304 - accuracy: 0.6982 - val_loss: 0.9859 - val_accuracy: 0.6156\n",
      "Epoch 46/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.7037 - val_loss: 0.9982 - val_accuracy: 0.6062\n",
      "Epoch 47/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6989 - accuracy: 0.7052 - val_loss: 0.9980 - val_accuracy: 0.6281\n",
      "Epoch 48/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.7263 - val_loss: 0.9955 - val_accuracy: 0.6219\n",
      "Epoch 49/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.7185 - val_loss: 1.0016 - val_accuracy: 0.6250\n",
      "Epoch 50/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7193 - val_loss: 1.0073 - val_accuracy: 0.6219\n",
      "Epoch 51/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.7013 - val_loss: 1.0016 - val_accuracy: 0.6469\n",
      "Epoch 52/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.7170 - val_loss: 1.0221 - val_accuracy: 0.6219\n",
      "Epoch 53/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.7193 - val_loss: 1.0300 - val_accuracy: 0.6313\n",
      "Epoch 54/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.7263 - val_loss: 1.0069 - val_accuracy: 0.6344\n",
      "Epoch 55/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.7389 - val_loss: 1.0065 - val_accuracy: 0.6219\n",
      "Epoch 56/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.7224 - val_loss: 1.0080 - val_accuracy: 0.6313\n",
      "Epoch 57/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.7131 - val_loss: 1.0026 - val_accuracy: 0.6469\n",
      "Epoch 58/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.7271 - val_loss: 1.0145 - val_accuracy: 0.6250\n",
      "Epoch 59/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.7248 - val_loss: 1.0077 - val_accuracy: 0.6500\n",
      "Epoch 60/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7256 - val_loss: 1.0166 - val_accuracy: 0.6344\n",
      "Epoch 61/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.7263 - val_loss: 1.0225 - val_accuracy: 0.6250\n",
      "Epoch 62/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7396 - val_loss: 1.0130 - val_accuracy: 0.6469\n",
      "Epoch 63/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.7256 - val_loss: 1.0186 - val_accuracy: 0.6375\n",
      "Epoch 64/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.7240 - val_loss: 1.0346 - val_accuracy: 0.6313\n",
      "Epoch 65/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.7303 - val_loss: 1.0200 - val_accuracy: 0.6406\n",
      "Epoch 66/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.7287 - val_loss: 1.0251 - val_accuracy: 0.6344\n",
      "Epoch 67/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7412 - val_loss: 1.0452 - val_accuracy: 0.6438\n",
      "Epoch 68/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.7443 - val_loss: 1.0504 - val_accuracy: 0.6344\n",
      "Epoch 69/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.7475 - val_loss: 1.0544 - val_accuracy: 0.6219\n",
      "Epoch 70/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7396 - val_loss: 1.0342 - val_accuracy: 0.6313\n",
      "Epoch 71/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.7373 - val_loss: 1.0442 - val_accuracy: 0.6219\n",
      "Epoch 72/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.7467 - val_loss: 1.0473 - val_accuracy: 0.6438\n",
      "Epoch 73/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7404 - val_loss: 1.0473 - val_accuracy: 0.6313\n",
      "Epoch 74/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.7404 - val_loss: 1.0545 - val_accuracy: 0.6281\n",
      "Epoch 75/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7467 - val_loss: 1.0342 - val_accuracy: 0.6344\n",
      "Epoch 76/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.7522 - val_loss: 1.0333 - val_accuracy: 0.6375\n",
      "Epoch 77/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7396 - val_loss: 1.0579 - val_accuracy: 0.6344\n",
      "Epoch 78/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7349 - val_loss: 1.0601 - val_accuracy: 0.6156\n",
      "Epoch 79/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7482 - val_loss: 1.0699 - val_accuracy: 0.6125\n",
      "Epoch 80/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7396 - val_loss: 1.0669 - val_accuracy: 0.6375\n",
      "Epoch 81/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7522 - val_loss: 1.0689 - val_accuracy: 0.6281\n",
      "Epoch 82/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7522 - val_loss: 1.0617 - val_accuracy: 0.6406\n",
      "Epoch 83/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7631 - val_loss: 1.0482 - val_accuracy: 0.6344\n",
      "Epoch 84/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7733 - val_loss: 1.0714 - val_accuracy: 0.6469\n",
      "Epoch 85/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7553 - val_loss: 1.0744 - val_accuracy: 0.6344\n",
      "Epoch 86/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7694 - val_loss: 1.0837 - val_accuracy: 0.6531\n",
      "Epoch 87/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7373 - val_loss: 1.0689 - val_accuracy: 0.6469\n",
      "Epoch 88/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.7561 - val_loss: 1.0830 - val_accuracy: 0.6250\n",
      "Epoch 89/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7678 - val_loss: 1.0564 - val_accuracy: 0.6469\n",
      "Epoch 90/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7701 - val_loss: 1.0660 - val_accuracy: 0.6500\n",
      "Epoch 91/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7623 - val_loss: 1.0861 - val_accuracy: 0.6187\n",
      "Epoch 92/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7717 - val_loss: 1.0788 - val_accuracy: 0.6531\n",
      "Epoch 93/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7475 - val_loss: 1.0815 - val_accuracy: 0.6344\n",
      "Epoch 94/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7764 - val_loss: 1.0830 - val_accuracy: 0.6562\n",
      "Epoch 95/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7662 - val_loss: 1.0958 - val_accuracy: 0.6469\n",
      "Epoch 96/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7631 - val_loss: 1.1189 - val_accuracy: 0.6469\n",
      "Epoch 97/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.7678 - val_loss: 1.1115 - val_accuracy: 0.6313\n",
      "Epoch 98/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7748 - val_loss: 1.1039 - val_accuracy: 0.6375\n",
      "Epoch 99/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7701 - val_loss: 1.0982 - val_accuracy: 0.6406\n",
      "Epoch 100/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7772 - val_loss: 1.1222 - val_accuracy: 0.6406\n",
      "Epoch 101/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7756 - val_loss: 1.1327 - val_accuracy: 0.6313\n",
      "Epoch 102/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7733 - val_loss: 1.1208 - val_accuracy: 0.6187\n",
      "Epoch 103/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7834 - val_loss: 1.1301 - val_accuracy: 0.6375\n",
      "Epoch 104/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7717 - val_loss: 1.1212 - val_accuracy: 0.6375\n",
      "Epoch 105/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7920 - val_loss: 1.1112 - val_accuracy: 0.6344\n",
      "Epoch 106/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7795 - val_loss: 1.1184 - val_accuracy: 0.6219\n",
      "Epoch 107/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7780 - val_loss: 1.1064 - val_accuracy: 0.6469\n",
      "Epoch 108/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7819 - val_loss: 1.1336 - val_accuracy: 0.6313\n",
      "Epoch 109/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7780 - val_loss: 1.1418 - val_accuracy: 0.6281\n",
      "Epoch 110/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7858 - val_loss: 1.1252 - val_accuracy: 0.6438\n",
      "Epoch 111/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7858 - val_loss: 1.1284 - val_accuracy: 0.6562\n",
      "Epoch 112/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7772 - val_loss: 1.1275 - val_accuracy: 0.6281\n",
      "Epoch 113/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7811 - val_loss: 1.1360 - val_accuracy: 0.6375\n",
      "Epoch 114/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7858 - val_loss: 1.1336 - val_accuracy: 0.6469\n",
      "Epoch 115/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7889 - val_loss: 1.1392 - val_accuracy: 0.6531\n",
      "Epoch 116/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7881 - val_loss: 1.1647 - val_accuracy: 0.6531\n",
      "Epoch 117/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7952 - val_loss: 1.1425 - val_accuracy: 0.6375\n",
      "Epoch 118/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7920 - val_loss: 1.1521 - val_accuracy: 0.6438\n",
      "Epoch 119/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7897 - val_loss: 1.1397 - val_accuracy: 0.6344\n",
      "Epoch 120/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7905 - val_loss: 1.1566 - val_accuracy: 0.6406\n",
      "Epoch 121/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8038 - val_loss: 1.1528 - val_accuracy: 0.6500\n",
      "Epoch 122/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7936 - val_loss: 1.1656 - val_accuracy: 0.6562\n",
      "Epoch 123/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8131 - val_loss: 1.1763 - val_accuracy: 0.6344\n",
      "Epoch 124/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7975 - val_loss: 1.1683 - val_accuracy: 0.6469\n",
      "Epoch 125/300\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.83 - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8084 - val_loss: 1.1749 - val_accuracy: 0.6344\n",
      "Epoch 126/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.8108 - val_loss: 1.1735 - val_accuracy: 0.6500\n",
      "Epoch 127/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.8006 - val_loss: 1.1773 - val_accuracy: 0.6313\n",
      "Epoch 128/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7905 - val_loss: 1.1720 - val_accuracy: 0.6406\n",
      "Epoch 129/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8038 - val_loss: 1.1918 - val_accuracy: 0.6406\n",
      "Epoch 130/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7928 - val_loss: 1.1942 - val_accuracy: 0.6531\n",
      "Epoch 131/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7975 - val_loss: 1.1683 - val_accuracy: 0.6562\n",
      "Epoch 132/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7975 - val_loss: 1.1758 - val_accuracy: 0.6406\n",
      "Epoch 133/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.8100 - val_loss: 1.1786 - val_accuracy: 0.6375\n",
      "Epoch 134/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8022 - val_loss: 1.1978 - val_accuracy: 0.6344\n",
      "Epoch 135/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7944 - val_loss: 1.1749 - val_accuracy: 0.6469\n",
      "Epoch 136/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8077 - val_loss: 1.1843 - val_accuracy: 0.6344\n",
      "Epoch 137/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8241 - val_loss: 1.2058 - val_accuracy: 0.6438\n",
      "Epoch 138/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8124 - val_loss: 1.1984 - val_accuracy: 0.6375\n",
      "Epoch 139/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8014 - val_loss: 1.2116 - val_accuracy: 0.6531\n",
      "Epoch 140/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.8045 - val_loss: 1.2155 - val_accuracy: 0.6469\n",
      "Epoch 141/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.8178 - val_loss: 1.2187 - val_accuracy: 0.6313\n",
      "Epoch 142/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.8077 - val_loss: 1.1998 - val_accuracy: 0.6438\n",
      "Epoch 143/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8186 - val_loss: 1.2035 - val_accuracy: 0.6500\n",
      "Epoch 144/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8178 - val_loss: 1.2153 - val_accuracy: 0.6406\n",
      "Epoch 145/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8194 - val_loss: 1.1961 - val_accuracy: 0.6406\n",
      "Epoch 146/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8225 - val_loss: 1.1930 - val_accuracy: 0.6562\n",
      "Epoch 147/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8225 - val_loss: 1.2098 - val_accuracy: 0.6531\n",
      "Epoch 148/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8170 - val_loss: 1.2300 - val_accuracy: 0.6500\n",
      "Epoch 149/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.8022 - val_loss: 1.2237 - val_accuracy: 0.6625\n",
      "Epoch 150/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8178 - val_loss: 1.2158 - val_accuracy: 0.6562\n",
      "Epoch 151/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.8194 - val_loss: 1.2346 - val_accuracy: 0.6313\n",
      "Epoch 152/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8186 - val_loss: 1.2261 - val_accuracy: 0.6344\n",
      "Epoch 153/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.8178 - val_loss: 1.2458 - val_accuracy: 0.6469\n",
      "Epoch 154/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8217 - val_loss: 1.2404 - val_accuracy: 0.6313\n",
      "Epoch 155/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8303 - val_loss: 1.2454 - val_accuracy: 0.6500\n",
      "Epoch 156/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8155 - val_loss: 1.2531 - val_accuracy: 0.6562\n",
      "Epoch 157/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8217 - val_loss: 1.2406 - val_accuracy: 0.6469\n",
      "Epoch 158/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8194 - val_loss: 1.2612 - val_accuracy: 0.6500\n",
      "Epoch 159/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.8327 - val_loss: 1.2488 - val_accuracy: 0.6531\n",
      "Epoch 160/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8280 - val_loss: 1.2365 - val_accuracy: 0.6562\n",
      "Epoch 161/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8327 - val_loss: 1.2578 - val_accuracy: 0.6625\n",
      "Epoch 162/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8241 - val_loss: 1.2411 - val_accuracy: 0.6500\n",
      "Epoch 163/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8342 - val_loss: 1.2670 - val_accuracy: 0.6625\n",
      "Epoch 164/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8241 - val_loss: 1.2882 - val_accuracy: 0.6562\n",
      "Epoch 165/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8280 - val_loss: 1.2803 - val_accuracy: 0.6531\n",
      "Epoch 166/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8256 - val_loss: 1.2891 - val_accuracy: 0.6375\n",
      "Epoch 167/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8397 - val_loss: 1.2870 - val_accuracy: 0.6625\n",
      "Epoch 168/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8358 - val_loss: 1.2811 - val_accuracy: 0.6562\n",
      "Epoch 169/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8217 - val_loss: 1.2769 - val_accuracy: 0.6625\n",
      "Epoch 170/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8233 - val_loss: 1.2760 - val_accuracy: 0.6562\n",
      "Epoch 171/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8452 - val_loss: 1.2659 - val_accuracy: 0.6406\n",
      "Epoch 172/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.8546 - val_loss: 1.2798 - val_accuracy: 0.6656\n",
      "Epoch 173/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8170 - val_loss: 1.3013 - val_accuracy: 0.6469\n",
      "Epoch 174/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8358 - val_loss: 1.2952 - val_accuracy: 0.6438\n",
      "Epoch 175/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8389 - val_loss: 1.2763 - val_accuracy: 0.6562\n",
      "Epoch 176/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8280 - val_loss: 1.2925 - val_accuracy: 0.6531\n",
      "Epoch 177/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8405 - val_loss: 1.3055 - val_accuracy: 0.6531\n",
      "Epoch 178/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8405 - val_loss: 1.3330 - val_accuracy: 0.6469\n",
      "Epoch 179/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8241 - val_loss: 1.3052 - val_accuracy: 0.6469\n",
      "Epoch 180/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8468 - val_loss: 1.3209 - val_accuracy: 0.6500\n",
      "Epoch 181/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3837 - accuracy: 0.8468 - val_loss: 1.3332 - val_accuracy: 0.6406\n",
      "Epoch 182/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3802 - accuracy: 0.8491 - val_loss: 1.3154 - val_accuracy: 0.6469\n",
      "Epoch 183/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8522 - val_loss: 1.3367 - val_accuracy: 0.6406\n",
      "Epoch 184/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8382 - val_loss: 1.3399 - val_accuracy: 0.6531\n",
      "Epoch 185/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8335 - val_loss: 1.3137 - val_accuracy: 0.6469\n",
      "Epoch 186/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8530 - val_loss: 1.3285 - val_accuracy: 0.6531\n",
      "Epoch 187/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8499 - val_loss: 1.3450 - val_accuracy: 0.6375\n",
      "Epoch 188/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.8444 - val_loss: 1.3381 - val_accuracy: 0.6531\n",
      "Epoch 189/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8569 - val_loss: 1.3280 - val_accuracy: 0.6469\n",
      "Epoch 190/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8608 - val_loss: 1.3460 - val_accuracy: 0.6438\n",
      "Epoch 191/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8452 - val_loss: 1.3285 - val_accuracy: 0.6438\n",
      "Epoch 192/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8428 - val_loss: 1.3756 - val_accuracy: 0.6438\n",
      "Epoch 193/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8452 - val_loss: 1.3527 - val_accuracy: 0.6406\n",
      "Epoch 194/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8538 - val_loss: 1.3588 - val_accuracy: 0.6500\n",
      "Epoch 195/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8382 - val_loss: 1.3557 - val_accuracy: 0.6469\n",
      "Epoch 196/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8296 - val_loss: 1.3724 - val_accuracy: 0.6531\n",
      "Epoch 197/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8483 - val_loss: 1.3633 - val_accuracy: 0.6687\n",
      "Epoch 198/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8593 - val_loss: 1.3645 - val_accuracy: 0.6500\n",
      "Epoch 199/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8647 - val_loss: 1.3386 - val_accuracy: 0.6719\n",
      "Epoch 200/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3782 - accuracy: 0.8483 - val_loss: 1.3324 - val_accuracy: 0.6719\n",
      "Epoch 201/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8585 - val_loss: 1.3483 - val_accuracy: 0.6531\n",
      "Epoch 202/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8624 - val_loss: 1.3661 - val_accuracy: 0.6531\n",
      "Epoch 203/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8569 - val_loss: 1.3884 - val_accuracy: 0.6469\n",
      "Epoch 204/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3738 - accuracy: 0.8483 - val_loss: 1.4018 - val_accuracy: 0.6656\n",
      "Epoch 205/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8546 - val_loss: 1.3994 - val_accuracy: 0.6562\n",
      "Epoch 206/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8663 - val_loss: 1.3916 - val_accuracy: 0.6562\n",
      "Epoch 207/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8475 - val_loss: 1.4041 - val_accuracy: 0.6562\n",
      "Epoch 208/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8593 - val_loss: 1.4045 - val_accuracy: 0.6531\n",
      "Epoch 209/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8507 - val_loss: 1.4073 - val_accuracy: 0.6625\n",
      "Epoch 210/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8577 - val_loss: 1.4158 - val_accuracy: 0.6750\n",
      "Epoch 211/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8647 - val_loss: 1.4002 - val_accuracy: 0.6562\n",
      "Epoch 212/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8647 - val_loss: 1.3962 - val_accuracy: 0.6469\n",
      "Epoch 213/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8647 - val_loss: 1.4283 - val_accuracy: 0.6406\n",
      "Epoch 214/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8757 - val_loss: 1.3996 - val_accuracy: 0.6500\n",
      "Epoch 215/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8640 - val_loss: 1.3925 - val_accuracy: 0.6687\n",
      "Epoch 216/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8647 - val_loss: 1.4167 - val_accuracy: 0.6562\n",
      "Epoch 217/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8600 - val_loss: 1.4434 - val_accuracy: 0.6594\n",
      "Epoch 218/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8546 - val_loss: 1.4327 - val_accuracy: 0.6594\n",
      "Epoch 219/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8718 - val_loss: 1.4435 - val_accuracy: 0.6594\n",
      "Epoch 220/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8640 - val_loss: 1.4245 - val_accuracy: 0.6594\n",
      "Epoch 221/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8460 - val_loss: 1.4413 - val_accuracy: 0.6625\n",
      "Epoch 222/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8671 - val_loss: 1.4528 - val_accuracy: 0.6594\n",
      "Epoch 223/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8663 - val_loss: 1.4584 - val_accuracy: 0.6500\n",
      "Epoch 224/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8655 - val_loss: 1.4365 - val_accuracy: 0.6562\n",
      "Epoch 225/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8655 - val_loss: 1.4351 - val_accuracy: 0.6531\n",
      "Epoch 226/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8640 - val_loss: 1.4677 - val_accuracy: 0.6500\n",
      "Epoch 227/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8585 - val_loss: 1.4464 - val_accuracy: 0.6656\n",
      "Epoch 228/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8522 - val_loss: 1.4527 - val_accuracy: 0.6406\n",
      "Epoch 229/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8858 - val_loss: 1.4456 - val_accuracy: 0.6625\n",
      "Epoch 230/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8663 - val_loss: 1.4288 - val_accuracy: 0.6594\n",
      "Epoch 231/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8796 - val_loss: 1.4598 - val_accuracy: 0.6562\n",
      "Epoch 232/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8819 - val_loss: 1.4689 - val_accuracy: 0.6469\n",
      "Epoch 233/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8600 - val_loss: 1.5147 - val_accuracy: 0.6625\n",
      "Epoch 234/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8718 - val_loss: 1.4627 - val_accuracy: 0.6531\n",
      "Epoch 235/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8788 - val_loss: 1.4938 - val_accuracy: 0.6531\n",
      "Epoch 236/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8640 - val_loss: 1.4633 - val_accuracy: 0.6594\n",
      "Epoch 237/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8874 - val_loss: 1.5074 - val_accuracy: 0.6687\n",
      "Epoch 238/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8843 - val_loss: 1.5170 - val_accuracy: 0.6531\n",
      "Epoch 239/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8718 - val_loss: 1.4700 - val_accuracy: 0.6469\n",
      "Epoch 240/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8749 - val_loss: 1.4891 - val_accuracy: 0.6438\n",
      "Epoch 241/300\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8686 - val_loss: 1.5154 - val_accuracy: 0.6406\n",
      "Epoch 242/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8819 - val_loss: 1.5062 - val_accuracy: 0.6500\n",
      "Epoch 243/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8913 - val_loss: 1.5164 - val_accuracy: 0.6625\n",
      "Epoch 244/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8827 - val_loss: 1.4954 - val_accuracy: 0.6469\n",
      "Epoch 245/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8718 - val_loss: 1.5007 - val_accuracy: 0.6656\n",
      "Epoch 246/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8812 - val_loss: 1.5186 - val_accuracy: 0.6500\n",
      "Epoch 247/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8843 - val_loss: 1.5294 - val_accuracy: 0.6500\n",
      "Epoch 248/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8741 - val_loss: 1.5167 - val_accuracy: 0.6562\n",
      "Epoch 249/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8827 - val_loss: 1.5085 - val_accuracy: 0.6562\n",
      "Epoch 250/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8843 - val_loss: 1.5400 - val_accuracy: 0.6469\n",
      "Epoch 251/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8694 - val_loss: 1.5180 - val_accuracy: 0.6625\n",
      "Epoch 252/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8890 - val_loss: 1.5190 - val_accuracy: 0.6531\n",
      "Epoch 253/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8757 - val_loss: 1.5627 - val_accuracy: 0.6500\n",
      "Epoch 254/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8804 - val_loss: 1.5590 - val_accuracy: 0.6594\n",
      "Epoch 255/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8772 - val_loss: 1.5278 - val_accuracy: 0.6500\n",
      "Epoch 256/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8726 - val_loss: 1.5421 - val_accuracy: 0.6531\n",
      "Epoch 257/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8812 - val_loss: 1.5558 - val_accuracy: 0.6594\n",
      "Epoch 258/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8843 - val_loss: 1.5387 - val_accuracy: 0.6562\n",
      "Epoch 259/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8788 - val_loss: 1.5372 - val_accuracy: 0.6594\n",
      "Epoch 260/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8858 - val_loss: 1.5567 - val_accuracy: 0.6750\n",
      "Epoch 261/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8944 - val_loss: 1.5527 - val_accuracy: 0.6625\n",
      "Epoch 262/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8804 - val_loss: 1.5786 - val_accuracy: 0.6562\n",
      "Epoch 263/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8788 - val_loss: 1.6057 - val_accuracy: 0.6625\n",
      "Epoch 264/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8890 - val_loss: 1.5764 - val_accuracy: 0.6531\n",
      "Epoch 265/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8882 - val_loss: 1.6329 - val_accuracy: 0.6500\n",
      "Epoch 266/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.8937 - val_loss: 1.5596 - val_accuracy: 0.6656\n",
      "Epoch 267/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2926 - accuracy: 0.8952 - val_loss: 1.5649 - val_accuracy: 0.6625\n",
      "Epoch 268/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8991 - val_loss: 1.5665 - val_accuracy: 0.6531\n",
      "Epoch 269/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8882 - val_loss: 1.5528 - val_accuracy: 0.6687\n",
      "Epoch 270/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8905 - val_loss: 1.5938 - val_accuracy: 0.6562\n",
      "Epoch 271/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8960 - val_loss: 1.5794 - val_accuracy: 0.6562\n",
      "Epoch 272/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8882 - val_loss: 1.5782 - val_accuracy: 0.6625\n",
      "Epoch 273/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8937 - val_loss: 1.5946 - val_accuracy: 0.6406\n",
      "Epoch 274/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8944 - val_loss: 1.6316 - val_accuracy: 0.6531\n",
      "Epoch 275/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8874 - val_loss: 1.5941 - val_accuracy: 0.6500\n",
      "Epoch 276/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8913 - val_loss: 1.6203 - val_accuracy: 0.6500\n",
      "Epoch 277/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8984 - val_loss: 1.6259 - val_accuracy: 0.6438\n",
      "Epoch 278/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8851 - val_loss: 1.6039 - val_accuracy: 0.6313\n",
      "Epoch 279/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8913 - val_loss: 1.6314 - val_accuracy: 0.6500\n",
      "Epoch 280/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8913 - val_loss: 1.6267 - val_accuracy: 0.6500\n",
      "Epoch 281/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8890 - val_loss: 1.6414 - val_accuracy: 0.6469\n",
      "Epoch 282/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.8968 - val_loss: 1.6095 - val_accuracy: 0.6594\n",
      "Epoch 283/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8929 - val_loss: 1.6215 - val_accuracy: 0.6656\n",
      "Epoch 284/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8968 - val_loss: 1.6185 - val_accuracy: 0.6656\n",
      "Epoch 285/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8952 - val_loss: 1.6008 - val_accuracy: 0.6719\n",
      "Epoch 286/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.8976 - val_loss: 1.6213 - val_accuracy: 0.6500\n",
      "Epoch 287/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8929 - val_loss: 1.6474 - val_accuracy: 0.6750\n",
      "Epoch 288/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.9077 - val_loss: 1.6540 - val_accuracy: 0.6531\n",
      "Epoch 289/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8968 - val_loss: 1.6598 - val_accuracy: 0.6594\n",
      "Epoch 290/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.8991 - val_loss: 1.6545 - val_accuracy: 0.6594\n",
      "Epoch 291/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.9077 - val_loss: 1.6650 - val_accuracy: 0.6500\n",
      "Epoch 292/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8952 - val_loss: 1.6791 - val_accuracy: 0.6687\n",
      "Epoch 293/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8882 - val_loss: 1.6578 - val_accuracy: 0.6438\n",
      "Epoch 294/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8819 - val_loss: 1.6372 - val_accuracy: 0.6594\n",
      "Epoch 295/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8898 - val_loss: 1.6317 - val_accuracy: 0.6625\n",
      "Epoch 296/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.9023 - val_loss: 1.6290 - val_accuracy: 0.6594\n",
      "Epoch 297/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.8960 - val_loss: 1.6934 - val_accuracy: 0.6531\n",
      "Epoch 298/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.9046 - val_loss: 1.6474 - val_accuracy: 0.6500\n",
      "Epoch 299/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8976 - val_loss: 1.6235 - val_accuracy: 0.6562\n",
      "Epoch 300/300\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.8952 - val_loss: 1.6522 - val_accuracy: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x199391c9d90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 300, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.008 0.984 0.008 0.   ]\n",
      " [0.    0.001 0.829 0.17  0.    0.   ]\n",
      " [0.    0.088 0.044 0.868 0.    0.   ]\n",
      " ...\n",
      " [0.    0.    0.97  0.03  0.001 0.   ]\n",
      " [0.    0.    0.98  0.02  0.    0.   ]\n",
      " [0.    0.018 0.732 0.25  0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "print(np.round(y_pred,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 1.6522 - accuracy: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.65220046043396, 0.671875]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1  1  0  0  0]\n",
      " [ 0  0  7  4  0  0]\n",
      " [ 0  3 94 33  3  0]\n",
      " [ 0  2 28 94  5  1]\n",
      " [ 0  0  0 14 26  0]\n",
      " [ 0  0  1  1  1  1]], shape=(6, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.math.confusion_matrix(np.argmax(y_test, axis=1),np.argmax(y_pred, axis=1)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d17ae21252f2b7fb43c77235fc47dd38ae5f55079d7f4853767dec83b7e048f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
